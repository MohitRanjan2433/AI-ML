{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyPmGEs/gcQ1+WM/k13LaI77"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"txn0q17yR9Mw","executionInfo":{"status":"ok","timestamp":1698429534060,"user_tz":-330,"elapsed":5579,"user":{"displayName":"Mohit Ranjan","userId":"08369355047002042713"}},"outputId":"a23620c5-20e3-41a5-e67e-72f7650190ff"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.3.2)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.6.3)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.1)\n"]}],"source":["pip install nltk"]},{"cell_type":"code","source":["pip install spacy"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YLm2hPAZSh4N","executionInfo":{"status":"ok","timestamp":1698429558505,"user_tz":-330,"elapsed":8128,"user":{"displayName":"Mohit Ranjan","userId":"08369355047002042713"}},"outputId":"e855f571-1b67-41ed-cb8c-f985e28e1ebd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (3.6.1)\n","Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.12)\n","Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.5)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.10)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.8)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.9)\n","Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy) (8.1.12)\n","Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.1.2)\n","Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.4.8)\n","Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.10)\n","Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.9.0)\n","Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.10.3)\n","Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (6.4.0)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (4.66.1)\n","Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.23.5)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.31.0)\n","Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.10.13)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.1.2)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy) (67.7.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (23.2)\n","Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.3.0)\n","Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.5.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2023.7.22)\n","Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.7.11)\n","Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.1.3)\n","Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy) (8.1.7)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy) (2.1.3)\n"]}]},{"cell_type":"code","source":["import spacy"],"metadata":{"id":"BXJCv5L0Smgr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["nlp = spacy.load(\"en_core_web_sm\")\n","\n","doc = nlp(\"Dr. Strange loves pav bhaji of mumbai. Hulk loves chat of delhi\")\n","\n","for sentence in doc.sents:\n","  print(sentence)"],"metadata":{"id":"alcjBZd6S0mV","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1698443063560,"user_tz":-330,"elapsed":602,"user":{"displayName":"Mohit Ranjan","userId":"08369355047002042713"}},"outputId":"f341fed0-7a35-4776-eb6a-9fb5b9580b97"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Dr. Strange loves pav bhaji of mumbai.\n","Hulk loves chat of delhi\n"]}]},{"cell_type":"code","source":["for sentence in doc.sents:\n","  for words in sentence:\n","    print(words)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Fhs8Z9luGKJq","executionInfo":{"status":"ok","timestamp":1698443118477,"user_tz":-330,"elapsed":12,"user":{"displayName":"Mohit Ranjan","userId":"08369355047002042713"}},"outputId":"0f1959af-d487-4fe3-c8e6-5900f807934c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Dr.\n","Strange\n","loves\n","pav\n","bhaji\n","of\n","mumbai\n",".\n","Hulk\n","loves\n","chat\n","of\n","delhi\n"]}]},{"cell_type":"code","source":["import nltk\n","\n","nltk.download('punkt')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9dFmcopJGahq","executionInfo":{"status":"ok","timestamp":1698443331535,"user_tz":-330,"elapsed":462,"user":{"displayName":"Mohit Ranjan","userId":"08369355047002042713"}},"outputId":"757ed9ea-fcc7-49c5-b02f-6686edd9d7de"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["from nltk.tokenize import  sent_tokenize\n","\n","sent_tokenize(\"Dr. Strange loves pav bhaji of mumbai. Hulk loves chat of delhi\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dnbGxP0AGeKR","executionInfo":{"status":"ok","timestamp":1698443334015,"user_tz":-330,"elapsed":10,"user":{"displayName":"Mohit Ranjan","userId":"08369355047002042713"}},"outputId":"41f71d8c-3a28-4339-a29a-8afaa73d15ca"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['Dr.', 'Strange loves pav bhaji of mumbai.', 'Hulk loves chat of delhi']"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["from nltk.tokenize import word_tokenize\n","\n","word_tokenize(\"Dr. Strange loves pav bhaji of mumbai. Hulk loves chat of delhi\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lTSpNmVIH5FE","executionInfo":{"status":"ok","timestamp":1698443566385,"user_tz":-330,"elapsed":539,"user":{"displayName":"Mohit Ranjan","userId":"08369355047002042713"}},"outputId":"3c203e7e-8a42-42f7-e57b-8eafc28b4bc0"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['Dr',\n"," '.',\n"," 'Strange',\n"," 'loves',\n"," 'pav',\n"," 'bhaji',\n"," 'of',\n"," 'mumbai',\n"," '.',\n"," 'Hulk',\n"," 'loves',\n"," 'chat',\n"," 'of',\n"," 'delhi']"]},"metadata":{},"execution_count":9}]},{"cell_type":"markdown","source":["Spacy Tokenization"],"metadata":{"id":"y0KfV1EWJxrz"}},{"cell_type":"code","source":["import spacy"],"metadata":{"id":"RPJbYjfsJzjJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["nlp = spacy.blank(\"en\")\n","\n","doc = nlp(\"Dr. Strange loves pav bhaji of mumbai as it costs only 2$ per plate\")\n","\n","for token in doc:\n","  print(token)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ec0JuQrWJw7a","executionInfo":{"status":"ok","timestamp":1698445387230,"user_tz":-330,"elapsed":34,"user":{"displayName":"Mohit Ranjan","userId":"08369355047002042713"}},"outputId":"008a3b45-4f84-4b9c-f0c8-5b804e7abf5a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Dr.\n","Strange\n","loves\n","pav\n","bhaji\n","of\n","mumbai\n","as\n","it\n","costs\n","only\n","2\n","$\n","per\n","plate\n"]}]},{"cell_type":"code","source":["doc[0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jH0Sn1X_KDaQ","executionInfo":{"status":"ok","timestamp":1698445387230,"user_tz":-330,"elapsed":32,"user":{"displayName":"Mohit Ranjan","userId":"08369355047002042713"}},"outputId":"8c57ad9d-5bfa-4de8-df3c-29c4a2de2267"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Dr."]},"metadata":{},"execution_count":31}]},{"cell_type":"code","source":["doc = nlp(\"Tony gave two $ to peter.\")"],"metadata":{"id":"j-i5U9tHLX6H"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["token0 = doc[0]\n","token0"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FNDOpkOmLfBA","executionInfo":{"status":"ok","timestamp":1698445387232,"user_tz":-330,"elapsed":32,"user":{"displayName":"Mohit Ranjan","userId":"08369355047002042713"}},"outputId":"5d37bbcd-222d-4e65-cee5-3b86e90b59aa"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Tony"]},"metadata":{},"execution_count":33}]},{"cell_type":"code","source":["type(token0)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"88xJgXPjLiV_","executionInfo":{"status":"ok","timestamp":1698445387232,"user_tz":-330,"elapsed":31,"user":{"displayName":"Mohit Ranjan","userId":"08369355047002042713"}},"outputId":"87652eca-db93-4824-8c28-36fbdbafbd82"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["spacy.tokens.token.Token"]},"metadata":{},"execution_count":34}]},{"cell_type":"code","source":["token0.is_alpha"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"V3hOGbxALkl9","executionInfo":{"status":"ok","timestamp":1698445387232,"user_tz":-330,"elapsed":30,"user":{"displayName":"Mohit Ranjan","userId":"08369355047002042713"}},"outputId":"4b2b1049-761b-4037-ec03-abaabc2af4c1"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":35}]},{"cell_type":"code","source":["token3 = doc[3]\n","token3"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"L-EjZ6DcLovs","executionInfo":{"status":"ok","timestamp":1698445387232,"user_tz":-330,"elapsed":28,"user":{"displayName":"Mohit Ranjan","userId":"08369355047002042713"}},"outputId":"dfc7b7c1-1ef0-4726-d360-b0127b68b175"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["$"]},"metadata":{},"execution_count":36}]},{"cell_type":"code","source":["token3.is_currency"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"L94IYEfhLuJz","executionInfo":{"status":"ok","timestamp":1698445387233,"user_tz":-330,"elapsed":27,"user":{"displayName":"Mohit Ranjan","userId":"08369355047002042713"}},"outputId":"b5f14933-9dc5-4f36-b7d8-bfe69ace068d"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":37}]},{"cell_type":"code","source":["dir(token3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a_aT85NgLzSV","executionInfo":{"status":"ok","timestamp":1698445387233,"user_tz":-330,"elapsed":25,"user":{"displayName":"Mohit Ranjan","userId":"08369355047002042713"}},"outputId":"93c63246-d913-402a-8dde-ccf4bf73cf25"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['_',\n"," '__bytes__',\n"," '__class__',\n"," '__delattr__',\n"," '__dir__',\n"," '__doc__',\n"," '__eq__',\n"," '__format__',\n"," '__ge__',\n"," '__getattribute__',\n"," '__gt__',\n"," '__hash__',\n"," '__init__',\n"," '__init_subclass__',\n"," '__le__',\n"," '__len__',\n"," '__lt__',\n"," '__ne__',\n"," '__new__',\n"," '__pyx_vtable__',\n"," '__reduce__',\n"," '__reduce_ex__',\n"," '__repr__',\n"," '__setattr__',\n"," '__sizeof__',\n"," '__str__',\n"," '__subclasshook__',\n"," '__unicode__',\n"," 'ancestors',\n"," 'check_flag',\n"," 'children',\n"," 'cluster',\n"," 'conjuncts',\n"," 'dep',\n"," 'dep_',\n"," 'doc',\n"," 'ent_id',\n"," 'ent_id_',\n"," 'ent_iob',\n"," 'ent_iob_',\n"," 'ent_kb_id',\n"," 'ent_kb_id_',\n"," 'ent_type',\n"," 'ent_type_',\n"," 'get_extension',\n"," 'has_dep',\n"," 'has_extension',\n"," 'has_head',\n"," 'has_morph',\n"," 'has_vector',\n"," 'head',\n"," 'i',\n"," 'idx',\n"," 'iob_strings',\n"," 'is_alpha',\n"," 'is_ancestor',\n"," 'is_ascii',\n"," 'is_bracket',\n"," 'is_currency',\n"," 'is_digit',\n"," 'is_left_punct',\n"," 'is_lower',\n"," 'is_oov',\n"," 'is_punct',\n"," 'is_quote',\n"," 'is_right_punct',\n"," 'is_sent_end',\n"," 'is_sent_start',\n"," 'is_space',\n"," 'is_stop',\n"," 'is_title',\n"," 'is_upper',\n"," 'lang',\n"," 'lang_',\n"," 'left_edge',\n"," 'lefts',\n"," 'lemma',\n"," 'lemma_',\n"," 'lex',\n"," 'lex_id',\n"," 'like_email',\n"," 'like_num',\n"," 'like_url',\n"," 'lower',\n"," 'lower_',\n"," 'morph',\n"," 'n_lefts',\n"," 'n_rights',\n"," 'nbor',\n"," 'norm',\n"," 'norm_',\n"," 'orth',\n"," 'orth_',\n"," 'pos',\n"," 'pos_',\n"," 'prefix',\n"," 'prefix_',\n"," 'prob',\n"," 'rank',\n"," 'remove_extension',\n"," 'right_edge',\n"," 'rights',\n"," 'sent',\n"," 'sent_start',\n"," 'sentiment',\n"," 'set_extension',\n"," 'set_morph',\n"," 'shape',\n"," 'shape_',\n"," 'similarity',\n"," 'subtree',\n"," 'suffix',\n"," 'suffix_',\n"," 'tag',\n"," 'tag_',\n"," 'tensor',\n"," 'text',\n"," 'text_with_ws',\n"," 'vector',\n"," 'vector_norm',\n"," 'vocab',\n"," 'whitespace_']"]},"metadata":{},"execution_count":38}]},{"cell_type":"code","source":["token2 = doc[2]\n","token2"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VmaanDvSL9mm","executionInfo":{"status":"ok","timestamp":1698445387233,"user_tz":-330,"elapsed":20,"user":{"displayName":"Mohit Ranjan","userId":"08369355047002042713"}},"outputId":"4d80ef73-4aac-45f1-80d3-52221a2e1365"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["two"]},"metadata":{},"execution_count":39}]},{"cell_type":"code","source":["token2.like_num"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iUa9oX6GMFBN","executionInfo":{"status":"ok","timestamp":1698445387233,"user_tz":-330,"elapsed":17,"user":{"displayName":"Mohit Ranjan","userId":"08369355047002042713"}},"outputId":"e1d3bf42-8fdf-4789-d46e-c99f95ee7a2c"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":40}]},{"cell_type":"code","source":["for token in doc:\n","  print(token, \"==>\", \"index: \", token.i,\n","        \"is_alpha:\", token.is_alpha,\n","        \"is_punct:\", token.is_punct,\n","        \"like_num:\", token.like_num,\n","        \"is_currency:\", token.is_currency,)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7bSwVDkUMda2","executionInfo":{"status":"ok","timestamp":1698445387233,"user_tz":-330,"elapsed":16,"user":{"displayName":"Mohit Ranjan","userId":"08369355047002042713"}},"outputId":"b171fba4-768c-4e33-aeb6-2aabd649b5cf"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Tony ==> index:  0 is_alpha: True is_punct: False like_num: False is_currency: False\n","gave ==> index:  1 is_alpha: True is_punct: False like_num: False is_currency: False\n","two ==> index:  2 is_alpha: True is_punct: False like_num: True is_currency: False\n","$ ==> index:  3 is_alpha: False is_punct: False like_num: False is_currency: True\n","to ==> index:  4 is_alpha: True is_punct: False like_num: False is_currency: False\n","peter ==> index:  5 is_alpha: True is_punct: False like_num: False is_currency: False\n",". ==> index:  6 is_alpha: False is_punct: True like_num: False is_currency: False\n"]}]},{"cell_type":"code","source":["with open(\"/content/student.txt\") as f:\n","  text = f.readlines()\n","\n","text"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MkaV1LlVOCCf","executionInfo":{"status":"ok","timestamp":1698445387233,"user_tz":-330,"elapsed":15,"user":{"displayName":"Mohit Ranjan","userId":"08369355047002042713"}},"outputId":"d3ad3caa-f078-42fd-9343-24df28e91454"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['Dayton high school, 8th grade students information\\n',\n"," '==================================================\\n',\n"," '\\n',\n"," 'Name\\tbirth day   \\temail\\n',\n"," '-----\\t------------\\t------\\n',\n"," 'Virat   5 June, 1882    virat@kohli.com\\n',\n"," 'Maria\\t12 April, 2001  maria@sharapova.com\\n',\n"," 'Serena  24 June, 1998   serena@williams.com \\n',\n"," 'Joe      1 May, 1997    joe@root.com']"]},"metadata":{},"execution_count":42}]},{"cell_type":"code","source":["text = ' '.join(text)\n","text"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":126},"id":"zn1VU3zkOdoA","executionInfo":{"status":"ok","timestamp":1698445387233,"user_tz":-330,"elapsed":12,"user":{"displayName":"Mohit Ranjan","userId":"08369355047002042713"}},"outputId":"1dc10f8a-0634-4f60-a11f-d5fa5a98075a"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'Dayton high school, 8th grade students information\\n ==================================================\\n \\n Name\\tbirth day   \\temail\\n -----\\t------------\\t------\\n Virat   5 June, 1882    virat@kohli.com\\n Maria\\t12 April, 2001  maria@sharapova.com\\n Serena  24 June, 1998   serena@williams.com \\n Joe      1 May, 1997    joe@root.com'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":28},{"output_type":"execute_result","data":{"text/plain":["'Dayton high school, 8th grade students information\\n ==================================================\\n \\n Name\\tbirth day   \\temail\\n -----\\t------------\\t------\\n Virat   5 June, 1882    virat@kohli.com\\n Maria\\t12 April, 2001  maria@sharapova.com\\n Serena  24 June, 1998   serena@williams.com \\n Joe      1 May, 1997    joe@root.com'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":43}]},{"cell_type":"code","source":["doc = nlp(text)\n","emails = []\n","for token in doc:\n","  if token.like_email:\n","    emails.append(token.text)\n","\n","emails"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"m-Twqb8CPKG7","executionInfo":{"status":"ok","timestamp":1698445570031,"user_tz":-330,"elapsed":492,"user":{"displayName":"Mohit Ranjan","userId":"08369355047002042713"}},"outputId":"4adf3a1b-be4e-4494-c277-ef69711d752b"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['virat@kohli.com',\n"," 'maria@sharapova.com',\n"," 'serena@williams.com',\n"," 'joe@root.com']"]},"metadata":{},"execution_count":46}]},{"cell_type":"code","source":["doc = nlp(\"gimme double cheese extra large healthy pizza\")\n","\n","tokens = [token.text for token in doc]\n","tokens"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-zUfRoy4P7_A","executionInfo":{"status":"ok","timestamp":1698446021014,"user_tz":-330,"elapsed":774,"user":{"displayName":"Mohit Ranjan","userId":"08369355047002042713"}},"outputId":"81f60495-d57c-45ca-d133-9167dc77e621"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['gimme', 'double', 'cheese', 'extra', 'large', 'healthy', 'pizza']"]},"metadata":{},"execution_count":47}]},{"cell_type":"code","source":["#special case\n","\n","from spacy.symbols import ORTH\n","\n","nlp.tokenizer.add_special_case(\"gimme\",[\n","    {ORTH: \"gim\"},\n","    {ORTH: \"me\"}\n","])\n","\n","doc = nlp(\"gimme double cheese extra large healthy pizza\")\n","\n","tokens = [token.text for token in doc]\n","tokens"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Z6LD251ORZSM","executionInfo":{"status":"ok","timestamp":1698446155583,"user_tz":-330,"elapsed":593,"user":{"displayName":"Mohit Ranjan","userId":"08369355047002042713"}},"outputId":"b61ceb78-a865-4955-96aa-0ad78784ee9a"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['gim', 'me', 'double', 'cheese', 'extra', 'large', 'healthy', 'pizza']"]},"metadata":{},"execution_count":48}]},{"cell_type":"markdown","source":["Excersice"],"metadata":{"id":"jRCnV8tGgvdC"}},{"cell_type":"code","source":["import spacy\n"],"metadata":{"id":"QDh_0Q1zg62J"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["transactions = \"Tony gave two $ to Peter, Bruce gave 500 € to Steve\"\n","\n","# TODO: Write code here\n","# Hint: Use token.i for the index of a token and token.is_currency for currency symbol detection"],"metadata":{"id":"bprVZ8NNgwhm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["nlp = spacy.load('en_core_web_sm')\n","\n","doc = nlp(transactions)\n","\n","for token in doc:\n","  if token.like_num and doc[token.i+1].is_currency:\n","    print(token.text, doc[token.i+1].text)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NJkR6C-Xgux1","executionInfo":{"status":"ok","timestamp":1698450706125,"user_tz":-330,"elapsed":658,"user":{"displayName":"Mohit Ranjan","userId":"08369355047002042713"}},"outputId":"6b59864c-378d-435c-f97d-013c51a30fb6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["two $\n","500 €\n"]}]},{"cell_type":"code","source":["text='''\n","Look for data to help you address the question. Governments are good\n","sources because data from public research is often freely available. Good\n","places to start include http://www.data.gov/, and http://www.science.\n","gov/, and in the United Kingdom, http://data.gov.uk/.\n","Two of my favorite data sets are the General Social Survey at http://www3.norc.org/gss+website/,\n","and the European Social Survey at http://www.europeansocialsurvey.org/.\n","'''"],"metadata":{"id":"PkXMIl88h3df"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["doc = nlp(text)\n","\n","for token in doc:\n","  if token.like_url:\n","    print(token)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BgZwhmxAjeRr","executionInfo":{"status":"ok","timestamp":1698450856267,"user_tz":-330,"elapsed":5,"user":{"displayName":"Mohit Ranjan","userId":"08369355047002042713"}},"outputId":"5d9f2ce1-7879-46b2-f144-32d9b046680f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["http://www.data.gov/\n","http://www.science\n","http://data.gov.uk/.\n","http://www3.norc.org/gss+website/\n","http://www.europeansocialsurvey.org/.\n"]}]},{"cell_type":"markdown","source":["Spacy Pipeline"],"metadata":{"id":"8wxVuZ_c7efG"}},{"cell_type":"code","source":["import spacy"],"metadata":{"id":"KaBnVhH_7fsF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["nlp = spacy.blank(\"en\")\n","\n","doc = nlp(\"Captain america ate 100$ of samosa. Then he said I can do this all day\")\n","\n","for token in doc:\n","  print(token)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pfuJ_ayw7ciw","executionInfo":{"status":"ok","timestamp":1698490855654,"user_tz":-330,"elapsed":16,"user":{"displayName":"Mohit Ranjan","userId":"08369355047002042713"}},"outputId":"e027a4f8-f51c-4f17-a678-9882a8d2d62b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Captain\n","america\n","ate\n","100\n","$\n","of\n","samosa\n",".\n","Then\n","he\n","said\n","I\n","can\n","do\n","this\n","all\n","day\n"]}]},{"cell_type":"code","source":["nlp.pipe_names"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6u_tQN4K8buO","executionInfo":{"status":"ok","timestamp":1698491074063,"user_tz":-330,"elapsed":11,"user":{"displayName":"Mohit Ranjan","userId":"08369355047002042713"}},"outputId":"2c76f546-8531-431f-939c-70ab5b2335e7"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[]"]},"metadata":{},"execution_count":3}]},{"cell_type":"code","source":["nlp = spacy.load(\"en_core_web_sm\")"],"metadata":{"id":"xoCkSppP9QhW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["nlp.pipe_names"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YymbEKim-Fcf","executionInfo":{"status":"ok","timestamp":1698491639601,"user_tz":-330,"elapsed":10,"user":{"displayName":"Mohit Ranjan","userId":"08369355047002042713"}},"outputId":"4ce8c7ad-dc80-4475-b909-3666f652c3d5"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['tok2vec', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer', 'ner']"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["doc = nlp(\"Captain america ate 100$ of samosa. Then he said I can do this all day\")\n","\n","for token in doc:\n","  print(token, \" | \", token.pos_, \" | \", token.lemma_)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iWxaqPCL-yTh","executionInfo":{"status":"ok","timestamp":1698491544085,"user_tz":-330,"elapsed":464,"user":{"displayName":"Mohit Ranjan","userId":"08369355047002042713"}},"outputId":"5b7dfe1c-cddd-4930-8292-c904673daeaf"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Captain  |  PROPN  |  Captain\n","america  |  PROPN  |  america\n","ate  |  VERB  |  eat\n","100  |  NUM  |  100\n","$  |  NUM  |  $\n","of  |  ADP  |  of\n","samosa  |  PROPN  |  samosa\n",".  |  PUNCT  |  .\n","Then  |  ADV  |  then\n","he  |  PRON  |  he\n","said  |  VERB  |  say\n","I  |  PRON  |  I\n","can  |  AUX  |  can\n","do  |  VERB  |  do\n","this  |  PRON  |  this\n","all  |  DET  |  all\n","day  |  NOUN  |  day\n"]}]},{"cell_type":"code","source":["doc = nlp(\"Tesla Inc is going to acquire twitter for $45 billion\")\n","\n","for ent in doc.ents:\n","  print(ent.text, \" | \", ent.label_, \" | \", spacy.explain(ent.label_))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tmXNgJ6Y_bkT","executionInfo":{"status":"ok","timestamp":1698491761820,"user_tz":-330,"elapsed":13,"user":{"displayName":"Mohit Ranjan","userId":"08369355047002042713"}},"outputId":"54e8c4ed-e241-49fa-c455-d35eac8dcca8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Tesla Inc  |  ORG  |  Companies, agencies, institutions, etc.\n","$45 billion  |  MONEY  |  Monetary values, including unit\n"]}]},{"cell_type":"code","source":["from spacy import displacy\n","\n","displacy.render(doc, style=\"ent\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":143},"id":"ztelrOtw_rWN","executionInfo":{"status":"ok","timestamp":1698492028156,"user_tz":-330,"elapsed":15,"user":{"displayName":"Mohit Ranjan","userId":"08369355047002042713"}},"outputId":"899a7a38-3383-4c78-dd17-427e7642324b"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\\n<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\\n    Tesla Inc\\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\\n</mark>\\n is going to acquire twitter for \\n<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\\n    $45 billion\\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">MONEY</span>\\n</mark>\\n</div>'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":14}]},{"cell_type":"markdown","source":["Stemming and Lemmatization-->"],"metadata":{"id":"QWmSnPigL4mk"}},{"cell_type":"code","source":["import nltk\n","import spacy"],"metadata":{"id":"YLNcTemnL9QI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from nltk.stem import PorterStemmer\n","\n","stemmer = PorterStemmer()"],"metadata":{"id":"1JfacswiL_3q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["words = [\"eating\", \"eats\", \"eat\", \"ate\", \"adjustable\", \"rafting\", \"ability\", \"meeting\"]\n","\n","for word in words:\n","  print(word, \"|\", stemmer.stem(word))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MXQJTbqbL4HM","executionInfo":{"status":"ok","timestamp":1698495044639,"user_tz":-330,"elapsed":15,"user":{"displayName":"Mohit Ranjan","userId":"08369355047002042713"}},"outputId":"816acdba-ba71-4294-f589-ad14ddd49bc1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["eating | eat\n","eats | eat\n","eat | eat\n","ate | ate\n","adjustable | adjust\n","rafting | raft\n","ability | abil\n","meeting | meet\n"]}]},{"cell_type":"code","source":["nlp = spacy.load(\"en_core_web_sm\")\n","\n","doc = nlp(\"eating eats eat ate adjustable rafting ability meeting better\")\n","\n","for token in doc:\n","  print(token, \"|\", token.lemma_, \"|\", token.lemma)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3qqeBuDkM28v","executionInfo":{"status":"ok","timestamp":1698495289133,"user_tz":-330,"elapsed":972,"user":{"displayName":"Mohit Ranjan","userId":"08369355047002042713"}},"outputId":"19cf7839-18a0-4d43-da0a-b41a0337f131"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["eating | eat | 9837207709914848172\n","eats | eat | 9837207709914848172\n","eat | eat | 9837207709914848172\n","ate | eat | 9837207709914848172\n","adjustable | adjustable | 6033511944150694480\n","rafting | raft | 7154368781129989833\n","ability | ability | 11565809527369121409\n","meeting | meeting | 14798207169164081740\n","better | well | 4525988469032889948\n"]}]},{"cell_type":"code","source":["ar = nlp.get_pipe('attribute_ruler')\n","\n","ar.add([[{\"TEXT\":\"Bro\"}], [{\"TEXT\":\"Brah\"}]], {\"LEMMA\": \"Brother\"})\n","\n","doc = nlp(\"Bro, you wanna go ? Brah, don't say no! I am exhausted\")\n","\n","for token in doc:\n","  print(token.text, \"|\", token.lemma_)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rZ8clr8xOiJh","executionInfo":{"status":"ok","timestamp":1698495762887,"user_tz":-330,"elapsed":8,"user":{"displayName":"Mohit Ranjan","userId":"08369355047002042713"}},"outputId":"570e883e-bbf9-407d-bd38-a2e47f23ebbd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Bro | Brother\n",", | ,\n","you | you\n","wanna | wanna\n","go | go\n","? | ?\n","Brah | Brother\n",", | ,\n","do | do\n","n't | not\n","say | say\n","no | no\n","! | !\n","I | I\n","am | be\n","exhausted | exhaust\n"]}]},{"cell_type":"markdown","source":["Excersice"],"metadata":{"id":"XVfvDwTsQDhx"}},{"cell_type":"code","source":["#let import necessary libraries and create the object\n","\n","#for nltk\n","import nltk\n","from nltk.stem import PorterStemmer\n","stemmer = PorterStemmer()\n","\n","#downloading all neccessary packages related to nltk\n","nltk.download('all')\n","\n","\n","#for spacy\n","import spacy\n","nlp = spacy.load(\"en_core_web_sm\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ROhvoLeyQEl6","executionInfo":{"status":"ok","timestamp":1698725938864,"user_tz":-330,"elapsed":49475,"user":{"displayName":"Mohit Ranjan","userId":"08369355047002042713"}},"outputId":"191767a8-3164-4a2e-a933-e152ebb9fc55"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading collection 'all'\n","[nltk_data]    | \n","[nltk_data]    | Downloading package abc to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/abc.zip.\n","[nltk_data]    | Downloading package alpino to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/alpino.zip.\n","[nltk_data]    | Downloading package averaged_perceptron_tagger to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping taggers/averaged_perceptron_tagger.zip.\n","[nltk_data]    | Downloading package averaged_perceptron_tagger_ru to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping\n","[nltk_data]    |       taggers/averaged_perceptron_tagger_ru.zip.\n","[nltk_data]    | Downloading package basque_grammars to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping grammars/basque_grammars.zip.\n","[nltk_data]    | Downloading package bcp47 to /root/nltk_data...\n","[nltk_data]    | Downloading package biocreative_ppi to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/biocreative_ppi.zip.\n","[nltk_data]    | Downloading package bllip_wsj_no_aux to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping models/bllip_wsj_no_aux.zip.\n","[nltk_data]    | Downloading package book_grammars to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping grammars/book_grammars.zip.\n","[nltk_data]    | Downloading package brown to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/brown.zip.\n","[nltk_data]    | Downloading package brown_tei to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/brown_tei.zip.\n","[nltk_data]    | Downloading package cess_cat to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/cess_cat.zip.\n","[nltk_data]    | Downloading package cess_esp to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/cess_esp.zip.\n","[nltk_data]    | Downloading package chat80 to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/chat80.zip.\n","[nltk_data]    | Downloading package city_database to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/city_database.zip.\n","[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/cmudict.zip.\n","[nltk_data]    | Downloading package comparative_sentences to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/comparative_sentences.zip.\n","[nltk_data]    | Downloading package comtrans to /root/nltk_data...\n","[nltk_data]    | Downloading package conll2000 to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/conll2000.zip.\n","[nltk_data]    | Downloading package conll2002 to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/conll2002.zip.\n","[nltk_data]    | Downloading package conll2007 to /root/nltk_data...\n","[nltk_data]    | Downloading package crubadan to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/crubadan.zip.\n","[nltk_data]    | Downloading package dependency_treebank to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/dependency_treebank.zip.\n","[nltk_data]    | Downloading package dolch to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/dolch.zip.\n","[nltk_data]    | Downloading package europarl_raw to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/europarl_raw.zip.\n","[nltk_data]    | Downloading package extended_omw to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    | Downloading package floresta to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/floresta.zip.\n","[nltk_data]    | Downloading package framenet_v15 to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/framenet_v15.zip.\n","[nltk_data]    | Downloading package framenet_v17 to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/framenet_v17.zip.\n","[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/gazetteers.zip.\n","[nltk_data]    | Downloading package genesis to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/genesis.zip.\n","[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/gutenberg.zip.\n","[nltk_data]    | Downloading package ieer to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/ieer.zip.\n","[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/inaugural.zip.\n","[nltk_data]    | Downloading package indian to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/indian.zip.\n","[nltk_data]    | Downloading package jeita to /root/nltk_data...\n","[nltk_data]    | Downloading package kimmo to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/kimmo.zip.\n","[nltk_data]    | Downloading package knbc to /root/nltk_data...\n","[nltk_data]    | Downloading package large_grammars to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping grammars/large_grammars.zip.\n","[nltk_data]    | Downloading package lin_thesaurus to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/lin_thesaurus.zip.\n","[nltk_data]    | Downloading package mac_morpho to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/mac_morpho.zip.\n","[nltk_data]    | Downloading package machado to /root/nltk_data...\n","[nltk_data]    | Downloading package masc_tagged to /root/nltk_data...\n","[nltk_data]    | Downloading package maxent_ne_chunker to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping chunkers/maxent_ne_chunker.zip.\n","[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping taggers/maxent_treebank_pos_tagger.zip.\n","[nltk_data]    | Downloading package moses_sample to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping models/moses_sample.zip.\n","[nltk_data]    | Downloading package movie_reviews to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/movie_reviews.zip.\n","[nltk_data]    | Downloading package mte_teip5 to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/mte_teip5.zip.\n","[nltk_data]    | Downloading package mwa_ppdb to /root/nltk_data...\n","[nltk_data]    |   Unzipping misc/mwa_ppdb.zip.\n","[nltk_data]    | Downloading package names to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/names.zip.\n","[nltk_data]    | Downloading package nombank.1.0 to /root/nltk_data...\n","[nltk_data]    | Downloading package nonbreaking_prefixes to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/nonbreaking_prefixes.zip.\n","[nltk_data]    | Downloading package nps_chat to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/nps_chat.zip.\n","[nltk_data]    | Downloading package omw to /root/nltk_data...\n","[nltk_data]    | Downloading package omw-1.4 to /root/nltk_data...\n","[nltk_data]    | Downloading package opinion_lexicon to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/opinion_lexicon.zip.\n","[nltk_data]    | Downloading package panlex_swadesh to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    | Downloading package paradigms to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/paradigms.zip.\n","[nltk_data]    | Downloading package pe08 to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/pe08.zip.\n","[nltk_data]    | Downloading package perluniprops to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping misc/perluniprops.zip.\n","[nltk_data]    | Downloading package pil to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/pil.zip.\n","[nltk_data]    | Downloading package pl196x to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/pl196x.zip.\n","[nltk_data]    | Downloading package porter_test to /root/nltk_data...\n","[nltk_data]    |   Unzipping stemmers/porter_test.zip.\n","[nltk_data]    | Downloading package ppattach to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/ppattach.zip.\n","[nltk_data]    | Downloading package problem_reports to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/problem_reports.zip.\n","[nltk_data]    | Downloading package product_reviews_1 to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/product_reviews_1.zip.\n","[nltk_data]    | Downloading package product_reviews_2 to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/product_reviews_2.zip.\n","[nltk_data]    | Downloading package propbank to /root/nltk_data...\n","[nltk_data]    | Downloading package pros_cons to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/pros_cons.zip.\n","[nltk_data]    | Downloading package ptb to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/ptb.zip.\n","[nltk_data]    | Downloading package punkt to /root/nltk_data...\n","[nltk_data]    |   Unzipping tokenizers/punkt.zip.\n","[nltk_data]    | Downloading package qc to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/qc.zip.\n","[nltk_data]    | Downloading package reuters to /root/nltk_data...\n","[nltk_data]    | Downloading package rslp to /root/nltk_data...\n","[nltk_data]    |   Unzipping stemmers/rslp.zip.\n","[nltk_data]    | Downloading package rte to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/rte.zip.\n","[nltk_data]    | Downloading package sample_grammars to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping grammars/sample_grammars.zip.\n","[nltk_data]    | Downloading package semcor to /root/nltk_data...\n","[nltk_data]    | Downloading package senseval to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/senseval.zip.\n","[nltk_data]    | Downloading package sentence_polarity to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/sentence_polarity.zip.\n","[nltk_data]    | Downloading package sentiwordnet to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/sentiwordnet.zip.\n","[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/shakespeare.zip.\n","[nltk_data]    | Downloading package sinica_treebank to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/sinica_treebank.zip.\n","[nltk_data]    | Downloading package smultron to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/smultron.zip.\n","[nltk_data]    | Downloading package snowball_data to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    | Downloading package spanish_grammars to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping grammars/spanish_grammars.zip.\n","[nltk_data]    | Downloading package state_union to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/state_union.zip.\n","[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/stopwords.zip.\n","[nltk_data]    | Downloading package subjectivity to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/subjectivity.zip.\n","[nltk_data]    | Downloading package swadesh to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/swadesh.zip.\n","[nltk_data]    | Downloading package switchboard to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/switchboard.zip.\n","[nltk_data]    | Downloading package tagsets to /root/nltk_data...\n","[nltk_data]    |   Unzipping help/tagsets.zip.\n","[nltk_data]    | Downloading package timit to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/timit.zip.\n","[nltk_data]    | Downloading package toolbox to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/toolbox.zip.\n","[nltk_data]    | Downloading package treebank to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/treebank.zip.\n","[nltk_data]    | Downloading package twitter_samples to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/twitter_samples.zip.\n","[nltk_data]    | Downloading package udhr to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/udhr.zip.\n","[nltk_data]    | Downloading package udhr2 to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/udhr2.zip.\n","[nltk_data]    | Downloading package unicode_samples to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/unicode_samples.zip.\n","[nltk_data]    | Downloading package universal_tagset to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping taggers/universal_tagset.zip.\n","[nltk_data]    | Downloading package universal_treebanks_v20 to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    | Downloading package vader_lexicon to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    | Downloading package verbnet to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/verbnet.zip.\n","[nltk_data]    | Downloading package verbnet3 to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/verbnet3.zip.\n","[nltk_data]    | Downloading package webtext to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/webtext.zip.\n","[nltk_data]    | Downloading package wmt15_eval to /root/nltk_data...\n","[nltk_data]    |   Unzipping models/wmt15_eval.zip.\n","[nltk_data]    | Downloading package word2vec_sample to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping models/word2vec_sample.zip.\n","[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n","[nltk_data]    | Downloading package wordnet2021 to /root/nltk_data...\n","[nltk_data]    | Downloading package wordnet2022 to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/wordnet2022.zip.\n","[nltk_data]    | Downloading package wordnet31 to /root/nltk_data...\n","[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/wordnet_ic.zip.\n","[nltk_data]    | Downloading package words to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/words.zip.\n","[nltk_data]    | Downloading package ycoe to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/ycoe.zip.\n","[nltk_data]    | \n","[nltk_data]  Done downloading collection all\n"]}]},{"cell_type":"markdown","source":["Exercise1:\n","\n","Convert these list of words into base form using Stemming and Lemmatization and observe the transformations\n","Write a short note on the words that have different base words using stemming and Lemmatization"],"metadata":{"id":"HG5OpmrAQSSt"}},{"cell_type":"code","source":["#using stemming in nltk\n","lst_words = ['running', 'painting', 'walking', 'dressing', 'likely', 'children', 'whom', 'good', 'ate', 'fishing']\n","\n","for word in lst_words:\n","  print(word, \"|\", stemmer.stem(word))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vDSwtediQSq4","executionInfo":{"status":"ok","timestamp":1698725938869,"user_tz":-330,"elapsed":101,"user":{"displayName":"Mohit Ranjan","userId":"08369355047002042713"}},"outputId":"522c4b60-9f8d-47a5-aaec-7e62e1d96804"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["running | run\n","painting | paint\n","walking | walk\n","dressing | dress\n","likely | like\n","children | children\n","whom | whom\n","good | good\n","ate | ate\n","fishing | fish\n"]}]},{"cell_type":"code","source":["#using lemmatization in spacy\n","doc = nlp(\"running painting walking dressing likely children whom good ate fishing\")\n","\n","for token in doc:\n","  print(token, \"|\", token.lemma_)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9cYsGp34QFn4","executionInfo":{"status":"ok","timestamp":1698725938870,"user_tz":-330,"elapsed":92,"user":{"displayName":"Mohit Ranjan","userId":"08369355047002042713"}},"outputId":"8752fb92-d525-4b15-9d21-1786cca995a3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["running | run\n","painting | paint\n","walking | walk\n","dressing | dress\n","likely | likely\n","children | child\n","whom | whom\n","good | good\n","ate | eat\n","fishing | fishing\n"]}]},{"cell_type":"markdown","source":["Observations\n","\n","Words that are different in stemming and lemmatization are:\n","\n","painting\n","likely\n","children\n","ate\n","fishing\n","As Stemming achieves the base word by removing the suffixes [ing, ly etc], so it successfully transform the words like 'painting', 'likely', 'fishing' and lemmatization fails for some words ending with suffixes here.\n","\n","As Lemmatization uses the dictionary meanings while converting to the base form, so words like 'children' and 'ate' are successfully transformed and stemming fails here."],"metadata":{"id":"ChYd7L_vRtC3"}},{"cell_type":"markdown","source":["Exercise2:\n","\n","convert the given text into it's base form using both stemming and lemmatization"],"metadata":{"id":"1-hTvX8rRxSX"}},{"cell_type":"code","source":["text = \"\"\"Latha is very multi talented girl.She is good at many skills like dancing, running, singing, playing.She also likes eating Pav Bhagi. she has a\n","habit of fishing and swimming too.Besides all this, she is a wonderful at cooking too.\n","\"\"\""],"metadata":{"id":"MLbOiAKuRxqx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import nltk\n","nltk.download('punkt')\n","from nltk.stem import PorterStemmer\n","stemmer = PorterStemmer()\n","#using stemming in nltk\n","\n","all_word_tokens = nltk.word_tokenize(text)\n","\n","\n","all_base_words = []\n","\n","for token in all_word_tokens:\n","  base_form = stemmer.stem(token)\n","  all_base_words.append(base_form)\n","\n","final_base_text = ' '.join(all_base_words)\n","print(final_base_text)"],"metadata":{"id":"dxLzhVnCRteO","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1698725938874,"user_tz":-330,"elapsed":87,"user":{"displayName":"Mohit Ranjan","userId":"08369355047002042713"}},"outputId":"00db17a4-f5f8-4666-92ce-a3ebce45badd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["latha is veri multi talent girl.sh is good at mani skill like danc , run , sing , playing.sh also like eat pav bhagi . she ha a habit of fish and swim too.besid all thi , she is a wonder at cook too .\n"]},{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"]}]},{"cell_type":"code","source":["#using lemmatisation in spacy\n","\n","doc = nlp(text)\n","all_base_words = []\n","\n","for token in doc:\n","  base_word = token.lemma_\n","  all_base_words.append(base_word)\n","\n","final_base_text = ' '.join(all_base_words)\n","print(final_base_text)"],"metadata":{"id":"D9tcGdpfQDFp","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1698726170324,"user_tz":-330,"elapsed":9,"user":{"displayName":"Mohit Ranjan","userId":"08369355047002042713"}},"outputId":"f896402a-2529-4478-aa01-b9236c29f326"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Latha be very multi talented girl . she be good at many skill like dancing , running , singing , play . she also like eat Pav Bhagi . she have a \n"," habit of fishing and swim too . besides all this , she be a wonderful at cook too . \n","\n"]}]},{"cell_type":"markdown","source":["Part of Speech --->"],"metadata":{"id":"Z3iqvVmE_7Cx"}},{"cell_type":"code","source":["import spacy"],"metadata":{"id":"60R1LCek_9eg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["nlp = spacy.load(\"en_core_web_sm\")"],"metadata":{"id":"v_PrHSyV9woA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["doc = nlp(\"Elon flew to mars yesterday. He carried biryani masala with him\")\n","\n","for token in doc:\n","  print(token, \"|\" , token.pos_, \"|\", spacy.explain(token.pos_))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rdwEWd_WAEvb","executionInfo":{"status":"ok","timestamp":1698726850853,"user_tz":-330,"elapsed":12,"user":{"displayName":"Mohit Ranjan","userId":"08369355047002042713"}},"outputId":"0c8d2de4-02a7-453e-d03b-5f53e44e24e4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Elon | PROPN | proper noun\n","flew | VERB | verb\n","to | ADP | adposition\n","mars | NOUN | noun\n","yesterday | NOUN | noun\n",". | PUNCT | punctuation\n","He | PRON | pronoun\n","carried | VERB | verb\n","biryani | ADJ | adjective\n","masala | NOUN | noun\n","with | ADP | adposition\n","him | PRON | pronoun\n"]}]},{"cell_type":"code","source":["doc =  nlp(\"Wow! Dr. Strange made 265 million $ on the very first day\")\n","\n","for token in doc:\n","  print(token, \"|\", token.pos_, \"|\", spacy.explain(token.pos_ ),\n","        \" | \", token.tag_, \" | \", spacy.explain(token.tag_))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QWGGgjxOArS3","executionInfo":{"status":"ok","timestamp":1698727235030,"user_tz":-330,"elapsed":593,"user":{"displayName":"Mohit Ranjan","userId":"08369355047002042713"}},"outputId":"5679d71d-616f-4945-a720-069b61b234af"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Wow | INTJ | interjection  |  UH  |  interjection\n","! | PUNCT | punctuation  |  .  |  punctuation mark, sentence closer\n","Dr. | PROPN | proper noun  |  NNP  |  noun, proper singular\n","Strange | PROPN | proper noun  |  NNP  |  noun, proper singular\n","made | VERB | verb  |  VBD  |  verb, past tense\n","265 | NUM | numeral  |  CD  |  cardinal number\n","million | NUM | numeral  |  CD  |  cardinal number\n","$ | NUM | numeral  |  CD  |  cardinal number\n","on | ADP | adposition  |  IN  |  conjunction, subordinating or preposition\n","the | DET | determiner  |  DT  |  determiner\n","very | ADV | adverb  |  RB  |  adverb\n","first | ADJ | adjective  |  JJ  |  adjective (English), other noun-modifier (Chinese)\n","day | NOUN | noun  |  NN  |  noun, singular or mass\n"]}]},{"cell_type":"code","source":["doc = nlp(\"He quits the job\")\n","\n","doc[1]\n","print(doc[1].text, \" | \", doc[1].tag_, \"|\", spacy.explain(doc[1].tag_))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"p1EzlgPCARdK","executionInfo":{"status":"ok","timestamp":1698727420126,"user_tz":-330,"elapsed":523,"user":{"displayName":"Mohit Ranjan","userId":"08369355047002042713"}},"outputId":"d89fb294-4636-436f-d7e3-c122298e63c5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["quits  |  VBZ | verb, 3rd person singular present\n"]}]},{"cell_type":"code","source":["doc = nlp(\"He quit the job\")\n","\n","doc[1]\n","print(doc[1].text, \" | \", doc[1].tag_, \"|\", spacy.explain(doc[1].tag_))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6exEom_tC2bg","executionInfo":{"status":"ok","timestamp":1698727438959,"user_tz":-330,"elapsed":13,"user":{"displayName":"Mohit Ranjan","userId":"08369355047002042713"}},"outputId":"67cd81ed-4770-49a8-88d4-1fa43a698960"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["quit  |  VBD | verb, past tense\n"]}]},{"cell_type":"code","source":["earnings_text=\"\"\"Microsoft Corp. today announced the following results for the quarter ended December 31, 2021, as compared to the corresponding period of last fiscal year:\n","\n","·         Revenue was $51.7 billion and increased 20%\n","·         Operating income was $22.2 billion and increased 24%\n","·         Net income was $18.8 billion and increased 21%\n","·         Diluted earnings per share was $2.48 and increased 22%\n","“Digital technology is the most malleable resource at the world’s disposal to overcome constraints and reimagine everyday work and life,” said Satya Nadella, chairman and chief executive officer of Microsoft. “As tech as a percentage of global GDP continues to increase, we are innovating and investing across diverse and growing markets, with a common underlying technology stack and an operating model that reinforces a common strategy, culture, and sense of purpose.”\n","“Solid commercial execution etc. represented by strong bookings growth driven by long-term Azure commitments, increased Microsoft Cloud revenue to $22.1 billion, up 32% year over year” said Amy Hood, executive vice president and chief financial officer of Microsoft.\"\"\"\n","\n","doc = nlp(earnings_text)\n","\n","filtered_tokens = []\n","\n","for token in doc:\n","  if token.pos_ not in [\"SPACE\", \"PUNCE\", \"X\"]:\n","    filtered_tokens.append(token)"],"metadata":{"id":"Ilrk1sXPC7EW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["`filtered_tokens[:10]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_UQYr3dSEnYt","executionInfo":{"status":"ok","timestamp":1698727929832,"user_tz":-330,"elapsed":13,"user":{"displayName":"Mohit Ranjan","userId":"08369355047002042713"}},"outputId":"30bdd5b8-32b1-4e41-832f-fc725d34c5ca"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[Microsoft,\n"," Corp.,\n"," today,\n"," announced,\n"," the,\n"," following,\n"," results,\n"," for,\n"," the,\n"," quarter]"]},"metadata":{},"execution_count":24}]},{"cell_type":"code","source":["count = doc.count_by(spacy.attrs.POS)\n","count"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DtEMpmexE18A","executionInfo":{"status":"ok","timestamp":1698728018609,"user_tz":-330,"elapsed":11,"user":{"displayName":"Mohit Ranjan","userId":"08369355047002042713"}},"outputId":"5185c3c2-ea7d-42d0-9399-6664870d4b12"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{96: 13,\n"," 92: 46,\n"," 100: 24,\n"," 90: 9,\n"," 85: 16,\n"," 93: 16,\n"," 97: 26,\n"," 98: 1,\n"," 84: 20,\n"," 103: 10,\n"," 87: 6,\n"," 99: 5,\n"," 89: 12,\n"," 86: 3,\n"," 94: 3,\n"," 95: 2,\n"," 101: 2}"]},"metadata":{},"execution_count":27}]},{"cell_type":"code","source":["for k,v in count.items():\n","  print(doc.vocab[k].text, \"|\", v)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4pYIs8oAFIau","executionInfo":{"status":"ok","timestamp":1698728137537,"user_tz":-330,"elapsed":14,"user":{"displayName":"Mohit Ranjan","userId":"08369355047002042713"}},"outputId":"f3373171-a04e-42fd-e3b3-4dc75ec55f45"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["PROPN | 13\n","NOUN | 46\n","VERB | 24\n","DET | 9\n","ADP | 16\n","NUM | 16\n","PUNCT | 26\n","SCONJ | 1\n","ADJ | 20\n","SPACE | 10\n","AUX | 6\n","SYM | 5\n","CCONJ | 12\n","ADV | 3\n","PART | 3\n","PRON | 2\n","X | 2\n"]}]},{"cell_type":"markdown","source":["Exercise for Spacy POS tutorial,\n","\n","You are parsing a news story from cnbc.com. News story is stores in news_story.txt which is available in this same folder on github. You need to,\n","Extract all NOUN tokens from this story. You will have to read the file in python first to collect all the text and then extract NOUNs in a python list\n","Extract all numbers (NUM POS type) in a python list\n","Print a count of all POS tags in this story"],"metadata":{"id":"vuwtnk7yF9vr"}},{"cell_type":"code","source":["import spacy"],"metadata":{"id":"z3ezWDTCF-l-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["nlp = spacy.load(\"en_core_web_sm\")"],"metadata":{"id":"r5FAVAMcF9OO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["doc = nlp(\"\"\"Inflation rose again in April, continuing a climb that has pushed consumers to the brink and is threatening the economic expansion, the Bureau of Labor Statistics reported Wednesday.\n","\n","The consumer price index, a broad-based measure of prices for goods and services, increased 8.3% from a year ago, higher than the Dow Jones estimate for an 8.1% gain. That represented a slight ease from March’s peak but was still close to the highest level since the summer of 1982.\n","\n","Removing volatile food and energy prices, so-called core CPI still rose 6.2%, against expectations for a 6% gain, clouding hopes that inflation had peaked in March.\n","\n","The month-over-month gains also were higher than expectations — 0.3% on headline CPI versus the 0.2% estimate and a 0.6% increase for core, against the outlook for a 0.4% gain.\n","\n","The price gains also meant that workers continued to lose ground. Real wages adjusted for inflation decreased 0.1% on the month despite a nominal increase of 0.3% in average hourly earnings. Over the past year, real earnings have dropped 2.6% even though average hourly earnings are up 5.5%.\n","\n","Inflation has been the single biggest threat to a recovery that began early in the Covid pandemic and saw the economy in 2021 stage its biggest single-year growth level since 1984. Rising prices at the pump and in grocery stores have been one problem, but inflation has spread beyond those two areas into housing, auto sales and a host of other areas.\n","\n","Federal Reserve officials have responded to the problem with two interest rate hikes so far this year and pledges of more until inflation comes down to the central bank’s 2% goal. However, Wednesday’s data shows that the Fed has a big job ahead.\n","\n","Credits: cnbc.com\"\"\")"],"metadata":{"id":"G9n1SPrbGO3o"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["all_Noun = []\n","\n","for token in doc:\n","  if token.pos_ in [\"NOUN\"]:\n","    all_Noun.append(token)"],"metadata":{"id":"5oaChdOXGbFP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["all_Noun"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jm8oxfRTG_jd","executionInfo":{"status":"ok","timestamp":1698728516372,"user_tz":-330,"elapsed":553,"user":{"displayName":"Mohit Ranjan","userId":"08369355047002042713"}},"outputId":"84e87603-adea-45ca-cde3-e86b2fbd9daf"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[Inflation,\n"," climb,\n"," consumers,\n"," brink,\n"," expansion,\n"," consumer,\n"," price,\n"," index,\n"," measure,\n"," prices,\n"," goods,\n"," services,\n"," %,\n"," year,\n"," estimate,\n"," %,\n"," gain,\n"," ease,\n"," peak,\n"," level,\n"," summer,\n"," food,\n"," energy,\n"," prices,\n"," core,\n"," %,\n"," expectations,\n"," %,\n"," gain,\n"," hopes,\n"," inflation,\n"," month,\n"," month,\n"," gains,\n"," expectations,\n"," %,\n"," headline,\n"," %,\n"," estimate,\n"," %,\n"," increase,\n"," core,\n"," outlook,\n"," %,\n"," gain,\n"," price,\n"," gains,\n"," workers,\n"," ground,\n"," wages,\n"," inflation,\n"," %,\n"," month,\n"," increase,\n"," %,\n"," earnings,\n"," year,\n"," earnings,\n"," %,\n"," earnings,\n"," %,\n"," Inflation,\n"," threat,\n"," recovery,\n"," pandemic,\n"," economy,\n"," stage,\n"," year,\n"," growth,\n"," level,\n"," prices,\n"," pump,\n"," grocery,\n"," stores,\n"," problem,\n"," inflation,\n"," areas,\n"," housing,\n"," auto,\n"," sales,\n"," host,\n"," areas,\n"," officials,\n"," problem,\n"," interest,\n"," rate,\n"," hikes,\n"," year,\n"," pledges,\n"," inflation,\n"," bank,\n"," %,\n"," goal,\n"," data,\n"," job,\n"," Credits]"]},"metadata":{},"execution_count":39}]},{"cell_type":"markdown","source":["Print a count of all POS tags"],"metadata":{"id":"fk6O75CtIU9U"}},{"cell_type":"code","source":["count = doc.count_by(spacy.attrs.POS)\n","count"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sS74_RhrHU0j","executionInfo":{"status":"ok","timestamp":1698728597755,"user_tz":-330,"elapsed":13,"user":{"displayName":"Mohit Ranjan","userId":"08369355047002042713"}},"outputId":"0cf42017-63a1-4e2a-9e0f-3a0ad7421ebe"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{92: 96,\n"," 100: 27,\n"," 86: 15,\n"," 85: 39,\n"," 96: 16,\n"," 97: 32,\n"," 90: 34,\n"," 95: 4,\n"," 87: 13,\n"," 89: 10,\n"," 84: 23,\n"," 103: 7,\n"," 93: 19,\n"," 94: 4,\n"," 98: 8,\n"," 101: 1}"]},"metadata":{},"execution_count":40}]},{"cell_type":"code","source":["for k,v in count.items():\n","  print(doc.vocab[k].text, \"|\", v)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rQNApqGTHWnX","executionInfo":{"status":"ok","timestamp":1698728638255,"user_tz":-330,"elapsed":9,"user":{"displayName":"Mohit Ranjan","userId":"08369355047002042713"}},"outputId":"56e7b208-836e-4546-bf9a-0f0799fdf39e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["NOUN | 96\n","VERB | 27\n","ADV | 15\n","ADP | 39\n","PROPN | 16\n","PUNCT | 32\n","DET | 34\n","PRON | 4\n","AUX | 13\n","CCONJ | 10\n","ADJ | 23\n","SPACE | 7\n","NUM | 19\n","PART | 4\n","SCONJ | 8\n","X | 1\n"]}]},{"cell_type":"code","source":["all_Num = []\n","\n","for token in doc:\n","  if token.pos_ in [\"NUM\"]:\n","    all_Num.append(token)\n","\n","all_Num"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pgTMZD02HjOt","executionInfo":{"status":"ok","timestamp":1698728749466,"user_tz":-330,"elapsed":15,"user":{"displayName":"Mohit Ranjan","userId":"08369355047002042713"}},"outputId":"e20cd813-c5c1-4428-86ce-f61e1ca049f8"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[8.3,\n"," 8.1,\n"," 1982,\n"," 6.2,\n"," 6,\n"," 0.3,\n"," 0.2,\n"," 0.6,\n"," 0.4,\n"," 0.1,\n"," 0.3,\n"," 2.6,\n"," 5.5,\n"," 2021,\n"," 1984,\n"," one,\n"," two,\n"," two,\n"," 2]"]},"metadata":{},"execution_count":42}]}]}